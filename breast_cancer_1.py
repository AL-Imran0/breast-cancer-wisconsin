# -*- coding: utf-8 -*-
"""Breast cancer-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16LmonNveTc8cXaWVF2FkplxsPC8KlnEA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report,
    roc_curve, roc_auc_score
)

url1 = ("https://archive.ics.uci.edu/ml/machine-learning-databases/"
        "breast-cancer-wisconsin/wdbc.data")
columns1 = ["id", "diagnosis"]
features = ["radius", "texture", "perimeter", "area", "smoothness",
            "compactness", "concavity", "concave_points", "symmetry",
            "fractal_dimension"]
stats = ["mean", "se", "worst"]
for stat in stats:
    for feat in features:
        columns1.append(f"{feat}_{stat}")
df1 = pd.read_csv(url1, header=None, names=columns1)
df1.drop(columns="id", inplace=True)
df1["diagnosis"] = df1["diagnosis"].map({'M': 1, 'B': 0})


url2 = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"
columns2 = ["id", "clump_thickness", "uniform_cell_size", "uniform_cell_shape",
            "marginal_adhesion", "single_epithelial_cell_size", "bare_nuclei",
            "bland_chromatin", "normal_nucleoli", "mitoses", "class"]
df2 = pd.read_csv(url2, names=columns2, na_values='?', header=None)
df2.drop(columns="id", inplace=True)
df2.dropna(inplace=True)
df2["bare_nuclei"] = df2["bare_nuclei"].astype(int)
df2["diagnosis"] = df2["class"].map({2: 0, 4: 1})
df2.drop(columns="class", inplace=True)
df2 = df2.rename(columns=lambda x: f"old_{x}" if x != "diagnosis" else x)


df1["source"] = "new"
df2["source"] = "old"
df_combined = pd.concat([df1, df2], axis=0, ignore_index=True).fillna(0)


X = df_combined.drop(columns=["diagnosis", "source"])
y = df_combined["diagnosis"]


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42)
print("Train shape:", X_train.shape, "Test shape:", X_test.shape)


rf = RandomForestClassifier(random_state=42)
lr = LogisticRegression(max_iter=1000, random_state=42)
rf.fit(X_train, y_train)
lr.fit(X_train, y_train)


rf_pred = rf.predict(X_test)
lr_pred = lr.predict(X_test)


def evaluate_model(y_true, y_pred, model_name):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    print(f"\n{model_name} Performance:")
    print(f"  Accuracy  = {acc:.3f}")
    print(f"  Precision = {prec:.3f}")
    print(f"  Recall    = {rec:.3f}")
    print(f"  F1 Score  = {f1:.3f}")

evaluate_model(y_test, rf_pred, "Random Forest")
evaluate_model(y_test, lr_pred, "Logistic Regression")


print("\nConfusion Matrix (Random Forest):\n", confusion_matrix(y_test, rf_pred))
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, rf_pred, target_names=["Benign", "Malignant"]))


corr = pd.DataFrame(X_scaled, columns=X.columns).corr()
plt.figure(figsize=(16, 12))
sns.heatmap(corr, cmap='coolwarm', center=0, square=True, cbar_kws={"shrink": 0.7})
plt.title("Feature Correlation Heatmap")
plt.tight_layout()
plt.show()


importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
top_n = 15
plt.figure(figsize=(10, 5))
plt.bar(range(top_n), importances[indices[:top_n]], color='orange', align='center')
plt.xticks(range(top_n), [X.columns[i] for i in indices[:top_n]], rotation=90)
plt.title("Top 15 Feature Importances (Random Forest)")
plt.ylabel("Importance")
plt.tight_layout()
plt.show()


y_prob_rf = rf.predict_proba(X_test)[:, 1]
y_prob_lr = lr.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)
auc_rf = roc_auc_score(y_test, y_prob_rf)
auc_lr = roc_auc_score(y_test, y_prob_lr)

plt.figure(figsize=(6, 6))
plt.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC = {auc_rf:.2f})", linewidth=2, color='darkorange')
plt.plot(fpr_lr, tpr_lr, label=f"Logistic Regression (AUC = {auc_lr:.2f})", linewidth=2, color='teal')
plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(5, 4))
sns.countplot(data=df_combined, x="diagnosis", hue="source", palette="Set2")
plt.title("Diagnosis Distribution by Dataset Source")
plt.xlabel("Diagnosis (0 = Benign, 1 = Malignant)")
plt.ylabel("Count")
plt.legend(title="Source")
plt.tight_layout()
plt.show()


top_features = [X.columns[i] for i in indices[:5]]
df_viz = pd.concat([pd.DataFrame(X_scaled, columns=X.columns), y.reset_index(drop=True)], axis=1)
plt.figure(figsize=(14, 8))
for i, col in enumerate(top_features):
    plt.subplot(2, 3, i+1)
    sns.boxplot(x='diagnosis', y=col, data=df_viz, palette="coolwarm")
    plt.title(f"{col} vs Diagnosis")
plt.tight_layout()
plt.show()


cm = confusion_matrix(y_test, rf_pred)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Benign", "Malignant"],
            yticklabels=["Benign", "Malignant"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest")
plt.tight_layout()
plt.show()


plt.figure(figsize=(14, 8))
for i, col in enumerate(top_features):
    plt.subplot(2, 3, i+1)
    sns.histplot(data=df_viz, x=col, hue="diagnosis", bins=30, kde=True, palette="Set1", element="step")
    plt.title(f"{col} Distribution")
plt.tight_layout()
plt.show()

sns.pairplot(df_viz[top_features + ["diagnosis"]], hue="diagnosis", corner=True, palette="Set1")
plt.suptitle("Pairplot of Top Features", y=1.02)
plt.show()